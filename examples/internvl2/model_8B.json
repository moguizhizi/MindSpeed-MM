{
    "model_id": "InternVL",
    "pre_process": true,
    "post_process": true,
    "add_text_encoder": false,
    "img_embedding_idx": 1,
    "downsample_ratio": 0.5,
    "select_layer": -1,
    "ps_version": "v2",
    "add_rmsnorm_offset": false,
    "img_context_token_id": 92546,
    "text_decoder": {
        "model_id": "internllm",
        "num_layers": 32,
        "pipeline_num_layers": [6, 9, 9, 8],
        "hidden_size": 4096,
        "num_attention_heads": 32,
        "num_query_groups": 8,
        "ffn_hidden_size": 14336,
        "kv_channels": 128,
        "hidden_dropout": 0.0,
        "attention_dropout": 0.0,
        "layernorm_epsilon": 1e-05,
        "normalization": "RMSNorm",
        "qk_layernorm": false,
        "add_bias_linear": false,
        "add_qkv_bias": false,
        "bias_activation_fusion": false,
        "gated_linear_unit": true,
        "init_method_std": 0.01,
        "apply_query_key_layer_scaling":false,
        "attention_softmax_in_fp32": true,
        "masked_softmax_fusion": false,
        "layernorm_zero_centered_gamma": false,
        "bias_dropout_fusion":false,
        "apply_rope_fusion": true,
        "memory_efficient_layer_norm": false,
        "max_position_embeddings": 4096,
        "fp16": false,
        "bf16": true,
        "params_dtype": "bf16",
        "fp16_lm_cross_entropy": false,
        "rotary_percent": 1.0,
        "position_embedding_type": "rope",
        "parallel_output": true,
        "initializer_factor": 0.1,
        "persist_layer_norm": true,
        "activation_func": "silu",
        "vocab_size": 92553,
        "rotary_base": 1000000
    },
    "image_encoder": {
        "vision_encoder": {
            "model_id": "InternViT",
            "num_layers": 24,
            "pipeline_num_layers": [24, 0, 0, 0],
            "hidden_size": 1024,
            "ffn_hidden_size": 4096,
            "num_attention_heads": 16,
            "num_channels": 3,
            "patch_size": 14,
            "image_size": 448,
            "add_qkv_bias": true,
            "qk_layernorm": false,
            "activation_func": "gelu",
            "normalization": "LayerNorm",
            "layernorm_epsilon": 1e-6,
            "hidden_dropout": 0.0,
            "drop_path_rate": 0.0,
            "attention_dropout": 0.0,
            "init_method_std": 0.02,
            "initializer_factor": 1.0,
            "output_hidden_states": false,
            "use_return_dict": false,
            "recompute_granularity": "full",
            "recompute_method": "uniform",
            "recompute_num_layers": 1,
            "params_dtype": "bf16",
            "post_layer_norm": false,
            "downsample_ratio": 0.5,
            "fp16": false,
            "bf16": true,
            "attention_softmax_in_fp32": false,
            "select_layer": -1,
            "ps_version": "v2",
            "freeze": true
        },
        "vision_projector": {
            "model_id": "InternVLMLP",
            "downsample_ratio": 0.5,
            "vit_hidden_size": 1024,
            "llm_hidden_size": 4096
        }
    },
    "text_encoder": null,
    "video_encoder": null
}