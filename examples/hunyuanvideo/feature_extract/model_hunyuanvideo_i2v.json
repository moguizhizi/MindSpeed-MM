{
    "ae": {
        "model_id": "autoencoder_kl_hunyuanvideo",
        "from_pretrained": "hunyuan-video-t2v-720p/vae/pytorch_model.pt",
        "dtype": "float32",
        "latent_channels": 16,
        "block_out_channels": [128, 256, 512, 512],
        "layers_per_block": 2,
        "in_channels": 3,
        "norm_num_groups": 32,
        "out_channels": 3,
        "sample_size": 256,
        "sample_tsize": 64,
        "down_block_types": [
            "DownEncoderBlockCausal3D",
            "DownEncoderBlockCausal3D",
            "DownEncoderBlockCausal3D",
            "DownEncoderBlockCausal3D"
        ],
        "up_block_types": [
            "UpDecoderBlockCausal3D", 
            "UpDecoderBlockCausal3D",
            "UpDecoderBlockCausal3D", 
            "UpDecoderBlockCausal3D"
        ],
        "scaling_factor": 0.476986,
        "time_compression_ratio": 4,
        "mid_block_add_attention": true,
        "act_fn": "silu",
        "enable_tiling": true,
        "i2v_processor": {
            "processor_id": "hunyuanvideo_i2v_processor",
            "sematic_cond_drop_p": 0.0,
            "processor_path": "llava-llama-3-8b-v1_1-transformers"
        }
    },
    "tokenizer": [
            {
                "autotokenizer_name": "hunyuanMLLmTokenizer",
                "hub_backend": "hf",
                "from_pretrained": "llava-llama-3-8b-v1_1-transformers",
                "model_max_length": 256,
                "template_id": "hyv-llm-encode-video-i2v",
                "template_file_path": "examples/hunyuanvideo/template.json"
            },
            {
                "autotokenizer_name": "CLIPTokenizer",
                "hub_backend": "hf",
                "from_pretrained": "clip-vit-large-patch14",
                "model_max_length": 77
            }
    ],
    "text_encoder": [
        {
            "model_id": "HunyuanMLLmModel",
            "dtype": "bf16",
            "from_pretrained": "llava-llama-3-8b-v1_1-transformers",
            "model_type": "LlavaForConditionalGeneration", 
            "hub_backend": "hf",
            "use_attention_mask": true,
            "hidden_state_skip_layer": 2,
            "output_key": "hidden_states",
            "template_id": "hyv-llm-encode-video-i2v",
            "template_file_path": "examples/hunyuanvideo/template.json",
            "using_kwargs": [
                "pixel_values"
            ]
        },
        {
            "model_id": "CLIP",
            "dtype": "fp16",
            "from_pretrained": "clip-vit-large-patch14",
            "hub_backend": "hf",
            "low_cpu_mem_usage": true,
            "use_attention_mask": true,
            "output_key": "pooler_output"
        }
    ]
}