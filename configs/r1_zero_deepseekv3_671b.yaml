defaults:
  - model:
      - deepseekv3_671b

megatron_training:
  model: deepseekv3_671b
  use_flash_attn: true
  shape_order: BNSD
  use_fused_rotary_pos_emb: true
  use_fused_rmsnorm: true
  use_fused_swiglu: true
  no_masked_softmax_fusion: true
  attention_softmax_in_fp32: true
  no_gradient_accumulation_fusion: true

  bf16: true
  sequence_parallel: true
  use_distributed_optimizer: true
  tokenizer_type: PretrainedFromHF
  tokenizer_name_or_path: ./data/models/deepseekv3
  global_batch_size: 12
  seq_length: 1024
  save_interval: 10000
  train_iters: 1000
  stage: ray_grpo
  attention_dropout: 0.0
  init_method_std: 0.01
  hidden_dropout: 0.0
  distributed_backend: nccl
  no_shared_storage: true
  variable_seq_lengths: true
  dataset_additional_keys: ['labels',]
  data_path: ./dataset/data
  split: 100,0,0

actor_config:
  model: deepseekv3_671b
  micro_batch_size: 1
  tensor_model_parallel_size: 32
  pipeline_model_parallel_size: 12
  num_layer_list: 6,5,5,5,5,5,5,5,5,5,5,5
  recompute_granularity: full
  recompute_method: uniform
  recompute_num_layers: 1
  lr: 1e-6
  lr_decay_style: constant
  min_lr: 0.0
  weight_decay: 0.0
  lr_warmup_fraction: 0.0
  clip_grad: 10000.0
  adam_beta1: 0.9
  adam_beta2: 0.95
  initial_loss_scale: 4096
  finetune: true
  load: ./ckpt_tp32pp12
  save: ./ckpt
  no_load_optim: true
  no_load_rng: true

ref_config:
  model: deepseekv3_671b
  tensor_model_parallel_size: 32
  pipeline_model_parallel_size: 1
  micro_batch_size: 1
  load: ./ckpt_tp32
  no_load_optim: true
  no_load_rng: true

reward_config:
  model: deepseekv3_671b
  micro_batch_size: 1

rl_config:
  blocking: false
  experience_count: 12
  gamma: 1.0
  lam: 0.95
  adv_estimator: group_norm
  kl_penalty: kl
  kl_ctrl_type: fixed
  init_kl_coef: 0.001
  missing_eos_penalty: 0.0
  mini_batch_size: 4
  max_prompt_length: 512
  epochs: 1
  clip_ratio: 0.2
  entropy_coeff: 0.001
  shuffle_minibatch: false
  n_samples_per_prompt: 4
  rule_reward: true
  verifier_function: ["acc", "format"]
  verifier_weight: [1.0, 0.5]
  verifier_parallel: 4
  num_cpus_for_local_task: 1.0
  actor_resource:
    num_npus: 384
  reference_resource:
    num_npus: 32

generate_config:
  # tokenizer相关配置
  trust_remote_code: true

  # 推理时的并行配置
  infer_tensor_parallel_size: 32
  infer_pipeline_parallel_size: 1
  infer_expert_parallel_size: 1

  # vllm 模型相关设置
  max_num_seqs: 1
  micro_batch_size: 1
  max_model_len: 4096
  dtype: "bfloat16"
  gpu_memory_utilization: 0.8
  enable_prefix_caching: false
  num_scheduler_steps: 1

  offload_train_optimizer: true
  offload_train_grad: true

  # 采样配置
  sampling_config:
    logprobs: 1
    max_tokens: 512
    top_p: 0.9
    top_k: 50
    min_p: 0.01
    temperature: 0.9
    detokenize: false
